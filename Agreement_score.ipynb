{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8e0dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "from nltk.internals import deprecated\n",
    "from nltk.metrics.distance import binary_distance\n",
    "from nltk.probability import ConditionalFreqDist, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dc066ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lr/zlwmj0rj26b912f9hjfxqj9c0000gn/T/ipykernel_1855/1939549919.py:3: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  Reliability = pd.read_csv('Reliability_study.csv', ';', usecols=['text','X_1','X_2','X_3', 'G_1', 'G_2', 'G_3'])\n"
     ]
    }
   ],
   "source": [
    "# Upload the reliability data as Pandas DataFrame \"Reliability\"\n",
    "\n",
    "Reliability = pd.read_csv('Reliability_study.csv', ';', usecols=['text','X_1','X_2','X_3', 'G_1', 'G_2', 'G_3'])\n",
    "\n",
    "# ISSUE: what about nan value? I think it should be expluded !\n",
    "\n",
    "# Merge coder's multiple annotations into single columns with tuples of annotations as values \n",
    "\n",
    "# Auxiliary functions !! I NEED TO ABSTRACT from X_1, etc.!! \n",
    "def create_combined_X(row):\n",
    "    return (row['X_1'], row['X_2'], row['X_3'])\n",
    "\n",
    "def create_combined_G(row):\n",
    "    return (row['G_1'], row['G_2'], row['G_3'])\n",
    "\n",
    "Reliability['X'] = Reliability.apply(create_combined_X, axis=1)\n",
    "Reliability['G'] = Reliability.apply(create_combined_G, axis=1)\n",
    "\n",
    "\n",
    "#print(Reliability['X'], Reliability['G'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d6a7201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MASI distance for set-valued items from NLTK Python library\n",
    "\n",
    "from nltk.metrics import masi_distance\n",
    "\n",
    "# Check MASI distances per each item annotated: seems to work!\n",
    "\n",
    "#for i in range(len(Reliability)):\n",
    "#    x = masi_distance(set(Reliability['X'][i]), set(Reliability['G'][i]))\n",
    "#    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "40ab8524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the lable frequencies for X annotation:\n",
      "dict_items([(('Lexicalized metaphor', nan, nan), 80), (('Humour', nan, nan), 1), ((nan, nan, nan), 50), (('Heuristic reasoning', nan, nan), 4), (('Visualization', nan, nan), 29), (('Visualization', 'Artistic metaphor', nan), 2), (('Persuasiveness', nan, nan), 10), (('Visualization', 'Persuasiveness', nan), 8), (('Persuasiveness', 'Heuristic reasoning', nan), 1), (('Visualization', 'Persuasiveness', 'Artistic metaphor'), 2), (('Persuasiveness', 'Artistic metaphor', 'Visualization'), 1), (('Visualization', 'Humour', nan), 3), (('Visualization', 'Artistic metaphor', 'Persuasiveness'), 1), (('Visualization', 'Explanation', nan), 2), (('Persuasiveness', 'Visualization', nan), 2), (('Persuasiveness', 'Argumentative metaphor', 'Visualization'), 1), (('Explanation', 'Visualization', nan), 1), (('Humour', 'Heuristic reasoning', nan), 1), (('Artistic metaphor', nan, nan), 1)])\n",
      "\n",
      "\n",
      "Here are the lable frequencies for G annotation:\n",
      "dict_items([(('Visualization', nan, nan), 38), (('Humour', nan, nan), 5), (('Heuristic reasoning', nan, nan), 10), (('Heuristic reasoning', 'Explanation', nan), 1), (('Visualization', 'Artistic metaphor', 'Heuristic reasoning'), 1), (('Lexicalized metaphor', nan, nan), 74), (('??', nan, nan), 13), (('Persuasiveness', nan, nan), 13), (('Lexicalized metaphor', 'Visualization', nan), 5), (('Artistic metaphor', 'Visualization', nan), 14), (('Explanation', 'Persuasiveness', 'Argumentative metaphor'), 1), (('Artistic metaphor', 'Heuristic reasoning', nan), 1), (('Visualization', 'Lexicalized metaphor', nan), 2), (('Explanation', 'Humour', nan), 1), (('Visualization', 'Persuasiveness', nan), 1), (('Argumentative metaphor', nan, nan), 3), (('Humour', 'Visualization', nan), 2), (('Argumentative metaphor', 'Persuasiveness', nan), 3), (('Social interaction', nan, nan), 1), (('Artistic metaphor', 'Explanation', 'Visualization'), 1), (('Explanation', nan, nan), 5), (('Persuasiveness', 'Argumentative metaphor', nan), 1), (('Heuristic reasoning', 'Lexicalized metaphor', nan), 1), (('Explanation', 'Lexicalized metaphor', nan), 1), (('Heuristic reasoning', 'Explanation', 'Visualization'), 1), (('Social interaction', 'Lexicalized metaphor', nan), 1)])\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries with frequencies of observation of each label per annotator\n",
    "\n",
    "label_freqs_X = FreqDist(Reliability['X'])\n",
    "label_freqs_G = FreqDist(Reliability['G'])\n",
    "\n",
    "\n",
    "print('Here are the lable frequencies for X annotation:')\n",
    "print(label_freqs_X.items())\n",
    "print(\"\\n\")\n",
    "print('Here are the lable frequencies for G annotation:')\n",
    "print(label_freqs_G.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6714d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge \"label_freqs_X\" and \"label_freqs_G\" into a single dictionary \"lable_freqs\"\n",
    "\n",
    "# Maybe I should first merge X and G and then turn it into FreqDist ? Seems to yeld the same result...\n",
    "# F = np.concatenate([Reliability['X'], Reliability['G']])\n",
    "# label_freqs_2 = FreqDist(F)\n",
    "\n",
    "label_freqs = label_freqs_X + label_freqs_G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "188ae69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Krippendorff's alpha with MASI distance and 2 coders\n",
    "\n",
    "# Adapted from NLTK library, based on '''Artstein and Poesio 2008'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "555f3fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6547669152046789"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Expected_disagreement(label_freqs):\n",
    "    \n",
    "    numer_units = sum(label_freqs.values())//2 # Number of annotated units\n",
    "    total_de = 0.0\n",
    "    for j, kj in label_freqs.items():\n",
    "        for l, kl in label_freqs.items():\n",
    "            total_de += float(kj * kl) * masi_distance(set(j), set(l)) # Here we need to convert to a set for MASI\n",
    "    de = 1.0 * total_de / (numer_units*2 * (numer_units*2 - 1)) # CHECK here, Poesio *2 while nltk without\n",
    "    return de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b752bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Observed_disagreement(Dataset, annotator_1, annotator_2, label_freqs):\n",
    "    \n",
    "        numer_units = sum(label_freqs.values())\n",
    "        total_do = 0.0  \n",
    "        for i in range(numer_units//2 - 1):\n",
    "            for j, kj in label_freqs.items():\n",
    "                for l, kl in label_freqs.items():\n",
    "                    \n",
    "                    if Dataset[annotator_1][i] == j and Dataset[annotator_2][i] == j:\n",
    "                        nkj = 2\n",
    "                    elif Dataset[annotator_1][i] == j and Dataset[annotator_2][i] != j:\n",
    "                        nkj = 1\n",
    "                    elif Dataset[annotator_1][i] != j and Dataset[annotator_2][i] == j:\n",
    "                        nkj = 1\n",
    "                    elif Dataset[annotator_1][i] != j and Dataset[annotator_2][i] != j:\n",
    "                        nkj = 0\n",
    "                        \n",
    "                    if Dataset[annotator_1][i] == l and Dataset[annotator_2][i] == l:\n",
    "                        nkl = 2\n",
    "                    elif Dataset[annotator_1][i] == l and Dataset[annotator_2][i] != l:\n",
    "                        nkl = 1\n",
    "                    elif Dataset[annotator_1][i] != l and Dataset[annotator_2][i] == l:\n",
    "                        nkl = 1\n",
    "                    elif Dataset[annotator_1][i] != l and Dataset[annotator_2][i] != l:\n",
    "                        nkl = 0\n",
    "                    \n",
    "                    total_do += float(nkj * nkl) * masi_distance(set(j), set(l))\n",
    "\n",
    "        do = total_do / (numer_units * 2)\n",
    "        return do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b32731a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6828610632099182"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def alpha(Dataset, annotator_1, annotator_2, label_freqs):\n",
    "\n",
    "        do = Observed_disagreement(Dataset, annotator_1, annotator_2, label_freqs)  # Observed disagreement\n",
    "        de = Expected_disagreement(label_freqs)  # Expected disagreement\n",
    "        k_alpha = 1.0 - do / de\n",
    "        return k_alpha\n",
    "    \n",
    "alpha(Reliability, 'X', 'G', label_freqs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
